<?xml version="1.0" encoding="utf-8" standalone="yes" ?>
<rss version="2.0" xmlns:atom="http://www.w3.org/2005/Atom">
  <channel>
    <title>Computer Vision on Osama Sakhi</title>
    <link>http://sakhi.es/tags/computer-vision/</link>
    <description>Recent content in Computer Vision on Osama Sakhi</description>
    <generator>Hugo -- gohugo.io</generator>
    <language>en-us</language>
    <copyright>Osama Sakhi &amp;copy; 2018</copyright>
    <lastBuildDate>Thu, 29 Nov 2018 10:00:00 +0000</lastBuildDate>
    
	<atom:link href="http://sakhi.es/tags/computer-vision/index.xml" rel="self" type="application/rss+xml" />
    
    
    <item>
      <title>SUMO Challenge</title>
      <link>http://sakhi.es/project/sumo/</link>
      <pubDate>Thu, 29 Nov 2018 10:00:00 +0000</pubDate>
      
      <guid>http://sakhi.es/project/sumo/</guid>
      <description>Background In Fall 2018, I joined Zhile Ren on the SUMO Challenge by Facebook.
The SUMO Challenge has several tracks for which we can compete for the best results, so our team decided to compete for the 3D Bounding Box track. That is, given 360 Degree RGB-Depth images, can we determine the 3D oriented bounding box for each of the items in the given scene?
There are over 100 included object categories, with a pretty skewed distribution: Approaches At first, Zhile and I were determined to use direct 3D detection approaches like using Clouds of Oriented Gradients (CoG).</description>
    </item>
    
  </channel>
</rss>