<<<<<<< HEAD
[{"authors":["admin"],"categories":null,"content":"I recently complted my Master\u0026rsquo;s degree in Computational Science \u0026amp; Engineering at the Georgia Institute of Technology. Previously, I\u0026rsquo;ve also completed a Bachelor\u0026rsquo;s degree in Computer Science from Georgia Tech, with specializations in Artificial Intelligence and Devices.\nOver the years I\u0026rsquo;ve conducted research in multiple labs, served as a TA several times, and worked as a back-end software engineer. Here are some of my highlights:\n Head TA for Intro. to Artificial Intelligence @ GT - Fall 2019 Research with Social Dynamics and Wellbeing Lab \u0026ndash; Summer 2019 - Present Computer Vision Intern \u0026ndash; Summer 2019 Research in 3D Object Detection \u0026ndash; Fall 2018 - Spring 2019 Software Engineer \u0026ndash; Summer 2017 to Summer 2018 Research in High Performance Computing \u0026ndash; Fall 2016 - Spring 2017 Instructor for Artificial Intelligence for DukeTIP \u0026ndash; Summer 2018 Delivered two TEDx talks on Mentorship \u0026ndash; Fall 2018 - Spring 2019  ","date":1559779200,"expirydate":-62135596800,"kind":"taxonomy","lang":"en","lastmod":1577373266,"objectID":"2525497d367e79493fd32b198b28f040","permalink":"/authors/admin/","publishdate":"0001-01-01T00:00:00Z","relpermalink":"/authors/admin/","section":"authors","summary":"I recently complted my Master\u0026rsquo;s degree in Computational Science \u0026amp; Engineering at the Georgia Institute of Technology. Previously, I\u0026rsquo;ve also completed a Bachelor\u0026rsquo;s degree in Computer Science from Georgia Tech, with specializations in Artificial Intelligence and Devices.\nOver the years I\u0026rsquo;ve conducted research in multiple labs, served as a TA several times, and worked as a back-end software engineer. Here are some of my highlights:\n Head TA for Intro. to Artificial Intelligence @ GT - Fall 2019 Research with Social Dynamics and Wellbeing Lab \u0026ndash; Summer 2019 - Present Computer Vision Intern \u0026ndash; Summer 2019 Research in 3D Object Detection \u0026ndash; Fall 2018 - Spring 2019 Software Engineer \u0026ndash; Summer 2017 to Summer 2018 Research in High Performance Computing \u0026ndash; Fall 2016 - Spring 2017 Instructor for Artificial Intelligence for DukeTIP \u0026ndash; Summer 2018 Delivered two TEDx talks on Mentorship \u0026ndash; Fall 2018 - Spring 2019  ","tags":null,"title":"Muhammad \"Osama\" Sakhi","type":"authors"},{"authors":null,"categories":null,"content":" Background I first took CS3600: Introduction to Artificial Intelligence in Fall 2015. In Fall 2016, I decided I wanted to TA for the course, and that was my first term as a TA. Being a new TA, I was still getting the hang of the material, being able to explain content in my own words, and help student debug all sorts of issues.\nIn Spring 2019, during my Master\u0026rsquo;s program, I decided to TA for the course again. This time, I had graduate-level experience in some of these topics such as Machine Learning, so I went in with much more confidence ready to help students grasp the material.\nFinally, in Fall 2019, I was chosen to be the Head TA for the course, which now had two sections with a total of 450+ students and 18 TAs.\nMass Autograder System During my term as a Head TA, one of the biggest challenges I faced was the issue of grading projects. With the number of students we had and the pace of the course, we simply couldn\u0026rsquo;t expect that all TAs would be able to grade a large block of students manually with only a few days notice, nor could we expect students to wait 3+ weeks to get feedback on their submissions.\nAlthough the projects we used for the course already came with test cases for students to validate their implementations, as TAs we still had to run our own tests to ensure that students didn\u0026rsquo;t trivialize the assignment by using functions or libraries we explicitly forbid. Additionally, we also wanted to run plagiarism detectors to ensure students didn\u0026rsquo;t use code they found off of the internet.\nThe previous solution we had for doing this in bits in pieces had a number of major issues:\n Brittle: it was unable to handle submissions that weren\u0026rsquo;t in the exact submission file hierarchy the assignment requested, even if all of the necessary source files were submitted. Unreliable: Sometimes the library would just not be able to handle common compression formats like _gzip_s, and these faulty submissions would have to be identified and regraded manually. Lacking key features: Graded submissions would be output in raw text files, meaning a TA would have to manually go in an enter those grades in the gradebook, all 450+ of them.  I decided it would be worth the time to create a new solution that would remedy all of these issues and would be easy enough for future Head TAs to run without any issues. Here are some of the key highlights of the implementation I completed the first three weeks into the semester:\n Automatic exporting of grades to the full gradebook Support for submissions with variations on the file hierarchies Easy extensible for future projects to be added to the course Improved plagiarism detection Extensive logging to ensure TAs can catch issues early on  Project Review Sessions Although this course doesn\u0026rsquo;t have formal recitations, the TAs for this course have typically taken it upon themselves to lead several review sessions throughout the semester for students to hear the material delivered at a slower pace by their peers as well as ask any questions they may have on course concepts. These sessions were mainly geared towards preparing students for the upcoming projects since they were such a large portion of the students\u0026rsquo; grades.\nIn previous semesters, the TAs had typically explained concepts verbally, with a bit of psuedocode given for common algorithms such as Djikstra\u0026rsquo;s Algorithm or the Bellman Update Equation, however I had always felt as though students were able to implement these in the projects and get by in the course without having a firm understanding of why they worked. Many students struggled heavily on the exams in those same concepts that they glossed over since they could implement the projects without that understanding.\nTo remedy this, I decided to create extensive review guides for the review sessions that could be used long after I had left Georgia Tech. With a handful of other TAs, we managed to produce well over 30 pages total of explanations of core concepts for the course.\nHere are the review guides we created:\n Graph Search Algorithms Reinforcement Learning Probabilitic Inference Neural Networks Decision Trees  In addition, these TAs and I led the hour-long review sessions for the projects where we presented this material to our students. Sessions typically had 30-40 students, and we addressed questions with illustrations, equations, or any other means of getting the students to understand the material.\nReflections It was a true honor and privilege to be the Head TA for this course. Not only did having so many students push me to refine my own understanding of even the subtle edge cases, but it also gave me the opportunity to bring what I have always felt were some very necessary changes to the course. I\u0026rsquo;m hopeful that the students were able to reap all of the benefits of these changes and that it truly inspires them to pursue research and careers in Artificial Intelligence.\n","date":1577404800,"expirydate":-62135596800,"kind":"section","lang":"en","lastmod":1577464735,"objectID":"0f6bd13149b199d3cab7bd6bf6a9c456","permalink":"/teaching/intro_to_ai/","publishdate":"2019-12-27T00:00:00Z","relpermalink":"/teaching/intro_to_ai/","section":"teaching","summary":"I served as the Head Teaching Assistant for CS3600 at Georgia Tech in Fall 2019. I was also a TA for the course in Fall 2016 and Spring 2019.","tags":null,"title":"Introduction to Artificial Intelligence","type":"docs"},{"authors":null,"categories":null,"content":" Background From June 2017 to June 2018, I worked as a Full-Time Software Engineer. I was all set to leave work at the end of the summer and return to Georgia Tech as a full-time Master\u0026rsquo;s Student for the Fall 2018 semester, but I suddenly got offered this unique opportunity by Duke TIP to teaching high schoolers Programming and AI. I jumped at the opportunity. Friday June 22nd, 2018 was my last day as an engineer, and Saturday morning on June 23rd I was already flying out to Houson for Rice University.\nThe next four weeks, I taught 2 classes:\n Applications, Algorithms, Computers: Modern Programming @ Rice University Artificial Intelligence @ Georgia Tech  Phase I The first class, I was a temp hire \u0026ndash; I was only there for the final week, since the previous instructor for the course was unable to teach that final week of the program. So, I was responsible for making sure these 18 students understood Python well enough that in just 5 days, I could teach them the basics of Web Development, and by the end of the week, each student would have used the Flask framework to make a really simple Twitter clone. Despite my limited time with the students, this was an overwhelming success.\nThe true hero was my Teaching Assistant, Noah Spiner, who held the class together all three weeks and made my transition into the classroom with these new kids a smooth one.\nJust 7 days after my arrival there, it was time to say goodbye. I had parent-teacher conferences with each of my students\u0026rsquo; parents. It was a wonderful experience \u0026ndash; my students genuinely felt that I\u0026rsquo;d impacted them in that short 1-week we were here together, and parents loved how I\u0026rsquo;d manaded to inspire their kids.\nPhase II This is the part of the teaching experience I was really psyched about \u0026ndash; the chance to teach high schoolers AI! I was tasked with crafting the curriculum end-to-end, including crafting syllabi, conducting lectures, creating assignments.\nYou can see my syllabus here. It offered a mix of the serious topics (Fundamentals of Python, Graph Search, Machine Learning, Natural Language Processing) and fun games and activities the class really enjoyed (Bot or Not?, Jeopardy Review sessions, AI Rap Battle, Robotics Lab Field Trip).\nThree whole weeks somehow flew by, and I could see from the looks on my students\u0026rsquo; faces that they felt the impact of my teaching. This was worth it all. This was worth the additional 2-3 hours I\u0026rsquo;d spend nightly preparing material for the next day, this was worth having to overcome my fear of standing in front of crowds, and this was definitely worth forgoing the additional month of full-time work experience I could\u0026rsquo;ve had instead.\nSyllabus I\u0026rsquo;ve published the syllabus here for you to use to create your own AI course. If you find any of the resources here to be helpful in teaching, I would love to hear about it! Feel free to email me about your experiences with the curriculum.\n","date":1567382400,"expirydate":-62135596800,"kind":"section","lang":"en","lastmod":1575161748,"objectID":"d0c7e26a360aa77062bb1097ed7de794","permalink":"/teaching/tip/","publishdate":"2019-09-02T00:00:00Z","relpermalink":"/teaching/tip/","section":"teaching","summary":"I served as an Instructor for DukeTIP during Summer 2018","tags":null,"title":"Duke TIP AI 2018","type":"docs"},{"authors":null,"categories":null,"content":" Project Links Here are links to the projects I used for my students during the Pathfinding portion of the course:\n Pacman Search Project  ","date":1567378800,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1575161748,"objectID":"81b8d98b2f05e30585aefe0545d37bfb","permalink":"/teaching/tip/pathfinding/","publishdate":"2019-09-02T00:00:00+01:00","relpermalink":"/teaching/tip/pathfinding/","section":"teaching","summary":" Project Links Here are links to the projects I used for my students during the Pathfinding portion of the course:\n Pacman Search Project  ","tags":null,"title":"Pathfinding","type":"docs"},{"authors":null,"categories":null,"content":" Project Links Here are links to the repos/projects I created or used for my students during the Machine Learning portion of the course:\n Repository for AI Machine Learning Experiment Walkthrough Cross-Validation Tutorial Naive Bayes by Hand Neural Networks by Hand Regression Tutorial  ","date":1567378800,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1575161748,"objectID":"8e6fd0b6755b5b6f0a6d2c339da08bf9","permalink":"/teaching/tip/ml/","publishdate":"2019-09-02T00:00:00+01:00","relpermalink":"/teaching/tip/ml/","section":"teaching","summary":" Project Links Here are links to the repos/projects I created or used for my students during the Machine Learning portion of the course:\n Repository for AI Machine Learning Experiment Walkthrough Cross-Validation Tutorial Naive Bayes by Hand Neural Networks by Hand Regression Tutorial  ","tags":null,"title":"Machine Learning","type":"docs"},{"authors":null,"categories":null,"content":" Project Links Here are links to the projects I created or used for my students during the Natural Language Processing portion of the course:\n Sentiment Analysis of Amazon Reviews  ","date":1567378800,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1575161748,"objectID":"46d986f702d48c341c686d6065088a68","permalink":"/teaching/tip/nlp/","publishdate":"2019-09-02T00:00:00+01:00","relpermalink":"/teaching/tip/nlp/","section":"teaching","summary":" Project Links Here are links to the projects I created or used for my students during the Natural Language Processing portion of the course:\n Sentiment Analysis of Amazon Reviews  ","tags":null,"title":"Natural Language Processing","type":"docs"},{"authors":null,"categories":null,"content":" Problem Statement  Given a hand-drawn sketch, retrieve the image instance that this sketch was drawn for   Related Work  Unsupervised Visual Representation Learning by Context Prediction The Sketchy Database: Learning to Retrieve Badly Drawn Bunnies Cross-modal Subspace Learning for fine-grained sketch-based image retrieval  Approach Assumptions  Aligned, paired images available. For this, we compute canny edges of the images in the PASCAL VOC dataset. Clustering image and sketch embeddings from a well-trained network will result in well-formed discrete clusters that are domain agnostic. The model that performs well on cross domain context prediction will perform well on the cross-domain image retrieval task.  Pre-text Task  We divide the image into 4 regions, with uneven spacing and jitter We then extract two patches, one from each domain, i.e. images from Pascal, and their Canny edges We finally compute the relative positioning of the patches using the context encoder  Image Retrieval  We first compute embeddings for the query sketch using AlexNet trained on the pretext We then perform a nearest neighbour search on the embeddings from the dataset of images We retrieve the nearest 5 and 10 images for top-5 and top-10 similarity scores  Results Visual Results  Here is one of our \u0026ldquo;bad\u0026rdquo; results \u0026ndash; we can see that the correct instance image is present in the retrieved images We can also see that the other bird result also captures similar pose as the sketch   Here is one of our \u0026ldquo;bad\u0026rdquo; results \u0026ndash; we see that the correct instance wasn\u0026rsquo;t retrieved Additionally, the correct class wasn\u0026rsquo;t retrieved either Note how despite the incorrect class/instance retrieval, we do see similarities in the pose and shape between the sketches and the retrieved images  Comparison to Baselines  Although our approach didn\u0026rsquo;t beat out our main baseline, the Sketchy database approach, we were able to beat out the feature pyramid approach with no supervision  Future Work  Study the effects of further training on pretext task Use context-encoder as pretraining for supervised image retreival models Use more sophisticated feature extractors (like GoogLeNet or VGG) that more recent Sketch-Based Image Retrieval methods use  ","date":1575115200,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1577378385,"objectID":"09f71a7ef9fbac9400ac26adc8f6f462","permalink":"/project/crossdom/","publishdate":"2019-11-30T12:00:00Z","relpermalink":"/project/crossdom/","section":"project","summary":"Cross Domain Context Prediction for Sketch-Based Image Retrieval","tags":["machine learning","self-supervised learning","unsupervised learning","computer vision","research"],"title":"Cross-Domain Context Prediction","type":"project"},{"authors":null,"categories":null,"content":" Background TODO\nApproaches TODO\nResults TODO\n","date":1574985600,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1575057414,"objectID":"e2d684b8317e387abdc9cf768ea2ac60","permalink":"/project/reduce/","publishdate":"2019-11-29T00:00:00Z","relpermalink":"/project/reduce/","section":"project","summary":"TODO","tags":["social computing","machine learning","natural language processing","research"],"title":"The REDUCE Project","type":"project"},{"authors":[],"categories":null,"content":"  Click on the Slides button above to view the built-in slides feature.   -- Background I was enrolled in a seminar course titled Learning with Limited Supervision in Fall 2019, and each class a group of students would lead a discussion on a chosen paper. For my discussion, I chose the Generative Adversarial Networks by Ian Goodfellow.\nI was tasked with not only presenting the methodology, but also debating the strengths of the paper against my colleague who presented the paper\u0026rsquo;s weaknesses.\n","date":1574946000,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1577378385,"objectID":"714b4ed2c70bde75299f686c0cfecd17","permalink":"/talks/gans/","publishdate":"2019-11-28T13:00:00Z","relpermalink":"/talks/gans/","section":"talks","summary":"A colleague and I presented the findings of the GAN paper by Ian Goodfellow to fellow graduate students.","tags":[],"title":"Generative Adversarial Networks Discussion","type":"talks"},{"authors":null,"categories":null,"content":" Background In Fall 2018, I joined Zhile Ren and Frank Dellaert on the SUMO Challenge by Facebook.\nThe SUMO Challenge has several tracks for which we can compete for the best results, so our team decided to compete for the 3D Bounding Box track. That is, given 360 Degree RGB-Depth images, can we determine the 3D oriented bounding box for each of the items in the given scene?\nThere are over 100 included object categories, with a pretty skewed distribution: Approaches At first, Zhile and I were determined to use direct 3D detection approaches like using Clouds of Oriented Gradients (CoG). However, the enormous size of the dataset (1+ Terrabyte) and image sizes (1024 x 6144 x 3 channels) immediately became problematic, both for training and inference.\nCoGs are great when the shape of the categories are easy to discern (i.e shapes that are not predominantly \u0026ldquo;box-like\u0026rdquo;), but in SUMO, we had many items that would have taken on very similar CoGs such as single_bed versus double_bed, tv_stand versus dresser, and so on.\nWe decided a good starting point would be to determine object locations in the 2D space, and see where we could go from there. We intended to then train for CoGs, but we had limited time with the SUMO challenge deadline being mid-December, so we decided to see how well we could perform by using the following pipeline:\n Project 3D bounding boxes into 2D space to generate a 2D dataset Train a Faster-R-CNN network to detect objects on the 2D dataset Project the 2D coordinates back into 3D, do some simple post-processing to prevent things like walls and floors from being in the bounding box Train Regressors to help correct the coordinates on a per-category basis  Results On December 18th, we found out that the SUMO challege deadline would be pushed back to January 14th. We continued work on step (3) but didn\u0026rsquo;t get very far in step (4), so our final pipeline consists of steps (1) through (3). We made our submission on Sunday, January 13th.\nWe found out that we were narrowly beat by the Princeton Vision Lab for 1st place, leaving us in 2nd place for our cateogry.\nVisual Results in 3D Below are our results in the 3D space. On the left, we have a red bounding box, which is our detection. On the right in green we have the ground truth bounding boxes for that same scene.\n Figure 1: Detection of a television with books in the tv stand. \n Figure 2: Detection of a shower. \n Figure 3: Detection of a door. \nVisual Results in 2D Below are some visual results we\u0026rsquo;ve gotten in the 2D space training the Faster-R-CNN network.\nAs you can see, the network performs fairly well. Mean AP was about 23% which is reasonable given the enormous dataset size and the skewed distribution. One aspect that particularly complicates this challenge are the walls and floors, which are object categories, but the coordinates are often outside of single-frame views, which is exactly what this network was trained to perform on.\n","date":1567382400,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1567487372,"objectID":"b9b26d2a3237290550ea3fd07978686a","permalink":"/project/sumo/","publishdate":"2019-09-02T00:00:00Z","relpermalink":"/project/sumo/","section":"project","summary":"Facebook's Scene Understanding and Modeling Challenge.","tags":["computer vision","machine learning","research"],"title":"SUMO Challenge","type":"project"},{"authors":null,"categories":null,"content":" Background: Graph Theory was among my favorite topics during my undergraduate studies, and in Fall 2016, I managed to find research that would build on my interests in that area as well as leverage the Systems background I had (from one of concentration areas: Devices).\nI joined Dr. Oded Green that term, and we began work immediately on Streaming Graphs (also known as Dynamic Graphs). These are graphs where the Nodes $V$ and Edges $E$ change over time.\nProblem: Betweenness Centrality on Streaming Graphs Betweenness Centrality(BC) is a measure of a node\u0026rsquo;s centrality in a graph based on it\u0026rsquo;s presence in shortest paths.\nThink of it as the hub that connects many different transportation lines. The more dependent other transportation lines are on a given hub, the more central that hub is to the network.\nOn a static graph, we can compute the BC values for each node pretty easily (in terms of time complexity). However, real-world graphs like Facebook\u0026rsquo;s Social Network Graph contain hundreds of millions of nodes and billions of edges. If we wanted up-to-date BC values for graphs of this scale, re-computing BC each time a node/edge is inserted or delete becomes infeasible.\nSo that\u0026rsquo;s our task: Given a graph and then a sequence of insertions/deletions, can we accurately compute the BC values without recomputing on the entire graph?\nApproach: We created a framework called cuStinger (a portmanteau of Cuda and Stinger), which served as the backbone of our adventure in getting Streaming BC going.\nUsing this framework (which saved us largely from writing repetitive Cuda code), we implemented the algorithm as described here.\nChallenges: Since we were using Nvidia GPUs and Cuda under the hood, we had various challenges with race conditions, mutex locks, and validating results.\nResults: By the end of that year, we managed to have a running version that handled most edge cases of streaming graphs. There were some we hadn\u0026rsquo;t implemented yet when I left the lab.\nA few weeks later, the lab moved onto a new framework (developed in-house with Oded and his lab), Hornet.\nLessons Learned  Parallel Computation comes with some challenges, be ready Advances in GPU programming are opening doors to many new areas ripe for exploration ALWAYS write tests to validate results (we compared our Streaming BC results to our Static BC at each insertion/deletion)  Tools Used  C/C++ Cuda cuStinger framework  ","date":1567296000,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1567485122,"objectID":"4ad9483811836389d75e55c8ef4ed7aa","permalink":"/project/hpc/","publishdate":"2019-09-01T00:00:00Z","relpermalink":"/project/hpc/","section":"project","summary":"Computing Betweenness Centrality on Streaming Graphs","tags":["hpc","research"],"title":"Betweenness Centrality for Streaming Graphs","type":"project"},{"authors":null,"categories":null,"content":"In Fall 2018, I decided to apply to be a speaker for TEDxGeorgiaTech's Fall speaker salon. I was chosen as one of the 6 speakers among 70 applicants.\nFor the 6 weeks that followed, I rewrote my speech several times over. I changed it drastically from what it started off as, added entirely new ideas, and overall realized that the focus of the talk had to be not my experience, but rather what others should take from it.\nFinally, on November 4th, 2018, my hard work paid off. I was the final speaker for the night, so I ended the show. My talk, Compounding Interest: How Instilling Drive Goes a Long Way tried to strike a delicate balance between being informative and being relatable. My focus was on the importance of instilling drive and the cascading effect that it had on educating society.\nYou can find my full talk here.\nAdditionally, I found out in February, 2019 that I was chosen among the 6 speakers from last Fall to speak again at the TedXGeorgiaTech Conference held on April 13th, 2019. I'm was ecstatic about the chance to revise my talk and give it one more time in front of an even larger crowd!\nThe revised talk was posted here in late July.\n","date":1567296000,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1567485122,"objectID":"beaaec28bcf9e35634a1be35667fa86b","permalink":"/post/ted/","publishdate":"2019-09-01T00:00:00Z","relpermalink":"/post/ted/","section":"post","summary":"In Fall 2018, I decided to apply to be a speaker for TEDxGeorgiaTech's Fall speaker salon. I was chosen as one of the 6 speakers among 70 applicants.\nFor the 6 weeks that followed, I rewrote my speech several times over. I changed it drastically from what it started off as, added entirely new ideas, and overall realized that the focus of the talk had to be not my experience, but rather what others should take from it.","tags":null,"title":"Speaking at TEDxGeorgiaTech's Fall 2018 Speaker Salon","type":"post"},{"authors":["Lyne P. Tchapmi","Daniel Huber","Richard Skarbez","Ilke Demir","Jimmy Wu","Xingyuan Sun","Muhammad \"Osama\" Sakhi","Zhile Ren","Shuran Song","Thomas Funkhouser","Silvio Savarese","Frank Dellaert"],"categories":null,"content":"","date":1559779200,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1577373266,"objectID":"51de3b4b0f038cfd845e2fa2218948a3","permalink":"/publication/sumo/","publishdate":"2017-01-01T00:00:00Z","relpermalink":"/publication/sumo/","section":"publication","summary":"Dataset paper for the Scene Understanding and Modeling (SUMO) Challenge by Facebook. To view the paper, please [email me](mailto:msakhi21@gmail.com).","tags":["research","computer vision","machine learning"],"title":"Sumo","type":"publication"},{"authors":[],"categories":[],"content":" Welcome to Slides Academic\nFeatures  Efficiently write slides in Markdown 3-in-1: Create, Present, and Publish your slides Supports speaker notes Mobile friendly slides  Controls  Next: Right Arrow or Space Previous: Left Arrow Start: Home Finish: End Overview: Esc Speaker notes: S Fullscreen: F Zoom: Alt + Click PDF Export: E  Code Highlighting Inline code: variable\nCode block:\nporridge = \u0026quot;blueberry\u0026quot; if porridge == \u0026quot;blueberry\u0026quot;: print(\u0026quot;Eating...\u0026quot;)  Math In-line math: $x + y = z$\nBlock math:\n$$ f\\left( x \\right) = \\;\\frac{{2\\left( {x + 4} \\right)\\left( {x - 4} \\right)}}{{\\left( {x + 4} \\right)\\left( {x + 1} \\right)}} $$\nFragments Make content appear incrementally\n{{% fragment %}} One {{% /fragment %}} {{% fragment %}} **Two** {{% /fragment %}} {{% fragment %}} Three {{% /fragment %}}  Press Space to play!\nOne  Two  Three \nA fragment can accept two optional parameters:\n class: use a custom style (requires definition in custom CSS) weight: sets the order in which a fragment appears  Speaker Notes Add speaker notes to your presentation\n{{% speaker_note %}} - Only the speaker can read these notes - Press `S` key to view {{% /speaker_note %}}  Press the S key to view the speaker notes!\n Only the speaker can read these notes Press S key to view   Themes  black: Black background, white text, blue links (default) white: White background, black text, blue links league: Gray background, white text, blue links beige: Beige background, dark text, brown links sky: Blue background, thin dark text, blue links   night: Black background, thick white text, orange links serif: Cappuccino background, gray text, brown links simple: White background, black text, blue links solarized: Cream-colored background, dark green text, blue links  Custom Slide Customize the slide style and background\n{{\u0026lt; slide background-image=\u0026quot;/img/boards.jpg\u0026quot; \u0026gt;}} {{\u0026lt; slide background-color=\u0026quot;#0000FF\u0026quot; \u0026gt;}} {{\u0026lt; slide class=\u0026quot;my-style\u0026quot; \u0026gt;}}  Custom CSS Example Let\u0026rsquo;s make headers navy colored.\nCreate assets/css/reveal_custom.css with:\n.reveal section h1, .reveal section h2, .reveal section h3 { color: navy; }  Questions? Ask\nDocumentation\n","date":1549324800,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1566957583,"objectID":"0e6de1a61aa83269ff13324f3167c1a9","permalink":"/slides/example/","publishdate":"2019-02-05T00:00:00Z","relpermalink":"/slides/example/","section":"slides","summary":"An introduction to using Academic's Slides feature.","tags":[],"title":"Slides","type":"slides"}]
=======
[{"authors":["admin"],"categories":null,"content":"I recently complted my Master's degree in Computational Science \u0026amp; Engineering at the Georgia Institute of Technology. Previously, I've also completed a Bachelor's degree in Computer Science from Georgia Tech, with specializations in Artificial Intelligence and Devices.\nOver the years I've conducted research in multiple labs, served as a TA several times, and worked as a back-end software engineer. Here are some of my highlights:\n Head TA for Intro. to Artificial Intelligence @ GT - Fall 2019 Research with Social Dynamics and Wellbeing Lab \u0026ndash; Summer 2019 - Present Computer Vision Intern \u0026ndash; Summer 2019 Research in 3D Object Detection \u0026ndash; Fall 2018 - Spring 2019 Backend Software Engineer \u0026ndash; Summer 2017 to Summer 2018 Research in High Performance Computing \u0026ndash; Fall 2016 - Spring 2017 Speaker for TEDxGeorgiaTech \u0026ndash; Fall 2018 - Spring 2019 Instructor for Artificial Intelligence for DukeTIP \u0026ndash; Summer 2018  ","date":1559779200,"expirydate":-62135596800,"kind":"taxonomy","lang":"en","lastmod":1577685153,"objectID":"2525497d367e79493fd32b198b28f040","permalink":"/authors/admin/","publishdate":"0001-01-01T00:00:00Z","relpermalink":"/authors/admin/","section":"authors","summary":"I recently complted my Master's degree in Computational Science \u0026amp; Engineering at the Georgia Institute of Technology. Previously, I've also completed a Bachelor's degree in Computer Science from Georgia Tech, with specializations in Artificial Intelligence and Devices.\nOver the years I've conducted research in multiple labs, served as a TA several times, and worked as a back-end software engineer. Here are some of my highlights:\n Head TA for Intro. to Artificial Intelligence @ GT - Fall 2019 Research with Social Dynamics and Wellbeing Lab \u0026ndash; Summer 2019 - Present Computer Vision Intern \u0026ndash; Summer 2019 Research in 3D Object Detection \u0026ndash; Fall 2018 - Spring 2019 Backend Software Engineer \u0026ndash; Summer 2017 to Summer 2018 Research in High Performance Computing \u0026ndash; Fall 2016 - Spring 2017 Speaker for TEDxGeorgiaTech \u0026ndash; Fall 2018 - Spring 2019 Instructor for Artificial Intelligence for DukeTIP \u0026ndash; Summer 2018  ","tags":null,"title":"Muhammad \"Osama\" Sakhi","type":"authors"},{"authors":null,"categories":null,"content":"Background I first took CS3600: Introduction to Artificial Intelligence in Fall 2015. In Fall 2016, I decided I wanted to TA for the course, and that was my first term as a TA. Being a new TA, I was still getting the hang of the material, being able to explain content in my own words, and help student debug all sorts of issues.\nIn Spring 2019, during my Master's program, I decided to TA for the course again. This time, I had graduate-level experience in some of these topics such as Machine Learning, so I went in with much more confidence ready to help students grasp the material.\nFinally, in Fall 2019, I was chosen to be the Head TA for the course, which now had two sections with a total of 450+ students and 18 TAs.\nMass Autograder System During my term as a Head TA, one of the biggest challenges I faced was the issue of grading projects. With the number of students we had and the pace of the course, we simply couldn't expect that all TAs would be able to grade a large block of students manually with only a few days notice, nor could we expect students to wait 3+ weeks to get feedback on their submissions.\nAlthough the projects we used for the course already came with test cases for students to validate their implementations, as TAs we still had to run our own tests to ensure that students didn't trivialize the assignment by using functions or libraries we explicitly forbid. Additionally, we also wanted to run plagiarism detectors to ensure students didn't use code they found off of the internet.\nThe previous solution we had for doing this in bits in pieces had a number of major issues:\n Brittle: it was unable to handle submissions that weren't in the exact submission file hierarchy the assignment requested, even if all of the necessary source files were submitted. Unreliable: Sometimes the library would just not be able to handle common compression formats like _gzip_s, and these faulty submissions would have to be identified and regraded manually. Lacking key features: Graded submissions would be output in raw text files, meaning a TA would have to manually go in an enter those grades in the gradebook, all 450+ of them.  I decided it would be worth the time to create a new solution that would remedy all of these issues and would be easy enough for future Head TAs to run without any issues. Here are some of the key highlights of the implementation I completed the first three weeks into the semester:\n Automatic exporting of grades to the full gradebook Support for submissions with variations on the file hierarchies Easy extensible for future projects to be added to the course Improved plagiarism detection Extensive logging to ensure TAs can catch issues early on  Project Review Sessions Although this course doesn't have formal recitations, the TAs for this course have typically taken it upon themselves to lead several review sessions throughout the semester for students to hear the material delivered at a slower pace by their peers as well as ask any questions they may have on course concepts. These sessions were mainly geared towards preparing students for the upcoming projects since they were such a large portion of the students\u0026rsquo; grades.\nIn previous semesters, the TAs had typically explained concepts verbally, with a bit of psuedocode given for common algorithms such as Djikstra's Algorithm or the Bellman Update Equation, however I had always felt as though students were able to implement these in the projects and get by in the course without having a firm understanding of why they worked. Many students struggled heavily on the exams in those same concepts that they glossed over since they could implement the projects without that understanding.\nTo remedy this, I decided to create extensive review guides for the review sessions that could be used long after I had left Georgia Tech. With a handful of other TAs, we managed to produce well over 30 pages total of explanations of core concepts for the course.\nHere are the review guides we created:\n Graph Search Algorithms Reinforcement Learning Probabilitic Inference Neural Networks Decision Trees  In addition, these TAs and I led the hour-long review sessions for the projects where we presented this material to our students. Sessions typically had 30-40 students, and we addressed questions with illustrations, equations, or any other means of getting the students to understand the material.\nReflections It was a true honor and privilege to be the Head TA for this course. Not only did having so many students push me to refine my own understanding of even the subtle edge cases, but it also gave me the opportunity to bring what I have always felt were some very necessary changes to the course. I'm hopeful that the students were able to reap all of the benefits of these changes and that it truly inspires them to pursue research and careers in Artificial Intelligence.\n","date":1577404800,"expirydate":-62135596800,"kind":"section","lang":"en","lastmod":1577464735,"objectID":"0f6bd13149b199d3cab7bd6bf6a9c456","permalink":"/teaching/intro_to_ai/","publishdate":"2019-12-27T00:00:00Z","relpermalink":"/teaching/intro_to_ai/","section":"teaching","summary":"I served as the Head Teaching Assistant for CS3600 at Georgia Tech in Fall 2019. I was also a TA for the course in Fall 2016 and Spring 2019.","tags":null,"title":"Introduction to Artificial Intelligence","type":"docs"},{"authors":null,"categories":null,"content":"Background From June 2017 to June 2018, I worked as a Full-Time Software Engineer. I was all set to leave work at the end of the summer and return to Georgia Tech as a full-time Master's Student for the Fall 2018 semester, but I suddenly got offered this unique opportunity by Duke TIP to teaching high schoolers Programming and AI. I jumped at the opportunity. Friday June 22nd, 2018 was my last day as an engineer, and Saturday morning on June 23rd I was already flying out to Houson for Rice University.\nThe next four weeks, I taught 2 classes:\n Applications, Algorithms, Computers: Modern Programming @ Rice University Artificial Intelligence @ Georgia Tech  Phase I The first class, I was a temp hire \u0026ndash; I was only there for the final week, since the previous instructor for the course was unable to teach that final week of the program. So, I was responsible for making sure these 18 students understood Python well enough that in just 5 days, I could teach them the basics of Web Development, and by the end of the week, each student would have used the Flask framework to make a really simple Twitter clone. Despite my limited time with the students, this was an overwhelming success.\nThe true hero was my Teaching Assistant, Noah Spiner, who held the class together all three weeks and made my transition into the classroom with these new kids a smooth one.\nJust 7 days after my arrival there, it was time to say goodbye. I had parent-teacher conferences with each of my students\u0026rsquo; parents. It was a wonderful experience \u0026ndash; my students genuinely felt that I'd impacted them in that short 1-week we were here together, and parents loved how I'd manaded to inspire their kids.\nPhase II This is the part of the teaching experience I was really psyched about \u0026ndash; the chance to teach high schoolers AI! I was tasked with crafting the curriculum end-to-end, including crafting syllabi, conducting lectures, creating assignments.\nYou can see my syllabus here. It offered a mix of the serious topics (Fundamentals of Python, Graph Search, Machine Learning, Natural Language Processing) and fun games and activities the class really enjoyed (Bot or Not?, Jeopardy Review sessions, AI Rap Battle, Robotics Lab Field Trip).\nThree whole weeks somehow flew by, and I could see from the looks on my students\u0026rsquo; faces that they felt the impact of my teaching. This was worth it all. This was worth the additional 2-3 hours I'd spend nightly preparing material for the next day, this was worth having to overcome my fear of standing in front of crowds, and this was definitely worth forgoing the additional month of full-time work experience I could've had instead.\nSyllabus I've published the syllabus here for you to use to create your own AI course. If you find any of the resources here to be helpful in teaching, I would love to hear about it! Feel free to email me about your experiences with the curriculum.\n","date":1567382400,"expirydate":-62135596800,"kind":"section","lang":"en","lastmod":1575161748,"objectID":"d0c7e26a360aa77062bb1097ed7de794","permalink":"/teaching/tip/","publishdate":"2019-09-02T00:00:00Z","relpermalink":"/teaching/tip/","section":"teaching","summary":"I served as an Instructor for DukeTIP during Summer 2018","tags":null,"title":"Duke TIP AI 2018","type":"docs"},{"authors":null,"categories":null,"content":"Project Links Here are links to the projects I used for my students during the Pathfinding portion of the course:\n Pacman Search Project  ","date":1567378800,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1575161748,"objectID":"81b8d98b2f05e30585aefe0545d37bfb","permalink":"/teaching/tip/pathfinding/","publishdate":"2019-09-02T00:00:00+01:00","relpermalink":"/teaching/tip/pathfinding/","section":"teaching","summary":"Project Links Here are links to the projects I used for my students during the Pathfinding portion of the course:\n Pacman Search Project  ","tags":null,"title":"Pathfinding","type":"docs"},{"authors":null,"categories":null,"content":"Project Links Here are links to the repos/projects I created or used for my students during the Machine Learning portion of the course:\n Repository for AI Machine Learning Experiment Walkthrough Cross-Validation Tutorial Naive Bayes by Hand Neural Networks by Hand Regression Tutorial  ","date":1567378800,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1575161748,"objectID":"8e6fd0b6755b5b6f0a6d2c339da08bf9","permalink":"/teaching/tip/ml/","publishdate":"2019-09-02T00:00:00+01:00","relpermalink":"/teaching/tip/ml/","section":"teaching","summary":"Project Links Here are links to the repos/projects I created or used for my students during the Machine Learning portion of the course:\n Repository for AI Machine Learning Experiment Walkthrough Cross-Validation Tutorial Naive Bayes by Hand Neural Networks by Hand Regression Tutorial  ","tags":null,"title":"Machine Learning","type":"docs"},{"authors":null,"categories":null,"content":"Project Links Here are links to the projects I created or used for my students during the Natural Language Processing portion of the course:\n Sentiment Analysis of Amazon Reviews  ","date":1567378800,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1575161748,"objectID":"46d986f702d48c341c686d6065088a68","permalink":"/teaching/tip/nlp/","publishdate":"2019-09-02T00:00:00+01:00","relpermalink":"/teaching/tip/nlp/","section":"teaching","summary":"Project Links Here are links to the projects I created or used for my students during the Natural Language Processing portion of the course:\n Sentiment Analysis of Amazon Reviews  ","tags":null,"title":"Natural Language Processing","type":"docs"},{"authors":null,"categories":null,"content":"Background The REDUCE project seeks to improve real-time estimation of suicide rates to better enable suicide prevention activities. We've partnered with the CDC to use historical trends with social media data to forecast future trends week-to-week.\nOne of the motivations for integrating social media data is the speed at which up-to-date social media can be obtained \u0026ndash; nearly instantly. In contrast, the CDC data we get will be a minimum of two years old because of all of the aggregation efforts needed by the CDC to publish this data.\nApproach For my role in this project, I've primarily worked on extracting meaninful signals from the social media data. Most of my time has been spent on the Twitter data we have, which comprises of over 9 million tweets focused around a selected set of keyword phrases related to depression, anxiety, and suicide.\nWith the tweets, I have built various embeddings for each tweet. These embeddings are aggregated in various ways to produce a representation for a week's worth of tweets at a time, and that representation is then fed into various regressors. The best trained regressor will be used as one learner in our final ensemble approach, which will consist of learners for the other data sources we have, such as CDC suicide data, Google Health data, Reddit language model data, etc.\nResults This project is ongoing, so we don't have much to report just yet. What we can say, however, is that the models built from the tweets seems to be very capable in our initial results. For one of our models, we found that the representation of tweets at a weekly granularity produced a model that performed nearly as well as the models built with just historical data (which is limited and is only available every 2 years).\n","date":1577664000,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1577683651,"objectID":"e2d684b8317e387abdc9cf768ea2ac60","permalink":"/project/reduce/","publishdate":"2019-12-30T00:00:00Z","relpermalink":"/project/reduce/","section":"project","summary":"Real-time Ensemble Data for Understanding Suicide Epidemiology","tags":["social computing","natural language processing","machine learning","research"],"title":"The REDUCE Project","type":"project"},{"authors":null,"categories":null,"content":"Problem Statement  Given a hand-drawn sketch, retrieve the image instance that this sketch was drawn for   Related Work  Unsupervised Visual Representation Learning by Context Prediction The Sketchy Database: Learning to Retrieve Badly Drawn Bunnies Cross-modal Subspace Learning for fine-grained sketch-based image retrieval  Approach Assumptions  Aligned, paired images available. For this, we compute canny edges of the images in the PASCAL VOC dataset. Clustering image and sketch embeddings from a well-trained network will result in well-formed discrete clusters that are domain agnostic. The model that performs well on cross domain context prediction will perform well on the cross-domain image retrieval task.  Pre-text Task  We divide the image into 4 regions, with uneven spacing and jitter We then extract two patches, one from each domain, i.e. images from Pascal, and their Canny edges We finally compute the relative positioning of the patches using the context encoder  Image Retrieval  We first compute embeddings for the query sketch using AlexNet trained on the pretext We then perform a nearest neighbour search on the embeddings from the dataset of images We retrieve the nearest 5 and 10 images for top-5 and top-10 similarity scores  Results Visual Results  Here is one of our \u0026ldquo;bad\u0026rdquo; results \u0026ndash; we can see that the correct instance image is present in the retrieved images We can also see that the other bird result also captures similar pose as the sketch   Here is one of our \u0026ldquo;bad\u0026rdquo; results \u0026ndash; we see that the correct instance wasn't retrieved Additionally, the correct class wasn't retrieved either Note how despite the incorrect class/instance retrieval, we do see similarities in the pose and shape between the sketches and the retrieved images  Comparison to Baselines  Although our approach didn't beat out our main baseline, the Sketchy database approach, we were able to beat out the feature pyramid approach with no supervision  Future Work  Study the effects of further training on pretext task Use context-encoder as pretraining for supervised image retreival models Use more sophisticated feature extractors (like GoogLeNet or VGG) that more recent Sketch-Based Image Retrieval methods use  ","date":1575115200,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1577378385,"objectID":"09f71a7ef9fbac9400ac26adc8f6f462","permalink":"/project/crossdom/","publishdate":"2019-11-30T12:00:00Z","relpermalink":"/project/crossdom/","section":"project","summary":"Cross Domain Context Prediction for Sketch-Based Image Retrieval","tags":["machine learning","self-supervised learning","unsupervised learning","computer vision","research"],"title":"Cross-Domain Context Prediction","type":"project"},{"authors":[],"categories":null,"content":"I was enrolled in a seminar course titled Learning with Limited Supervision in Fall 2019, and each class a group of students would lead a discussion on a chosen paper. For my discussion, I chose the Generative Adversarial Networks by Ian Goodfellow.\nI was tasked with not only presenting the methodology, but also debating the strengths of the paper against my colleague who presented the paper's weaknesses.\nDespite the paper being a seminal work in Computer Vision and in Deep Learning, there was plenty to discuss about the ideas presented in this paper since a few years have passed since its publishing, which allows us to look back and reflect on how these ideas have held up over the years.\n","date":1574946000,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1577683651,"objectID":"0054797171bcec14238160ccb785cb88","permalink":"/talk/gans/","publishdate":"2019-11-28T13:00:00Z","relpermalink":"/talk/gans/","section":"talk","summary":"A colleague and I presented the findings of the GAN paper by Ian Goodfellow to fellow graduate students.","tags":[],"title":"Generative Adversarial Networks Discussion","type":"talk"},{"authors":null,"categories":null,"content":"Background In Fall 2018, I joined Zhile Ren and Frank Dellaert on the SUMO Challenge by Facebook.\nThe SUMO Challenge has several tracks for which we can compete for the best results, so our team decided to compete for the 3D Bounding Box track. That is, given 360 Degree RGB-Depth images, can we determine the 3D oriented bounding box for each of the items in the given scene?\nThere are over 100 included object categories, with a pretty skewed distribution: Approaches At first, Zhile and I were determined to use direct 3D detection approaches like using Clouds of Oriented Gradients (CoG). However, the enormous size of the dataset (1+ Terrabyte) and image sizes (1024 x 6144 x 3 channels) immediately became problematic, both for training and inference.\nCoGs are great when the shape of the categories are easy to discern (i.e shapes that are not predominantly \u0026ldquo;box-like\u0026rdquo;), but in SUMO, we had many items that would have taken on very similar CoGs such as single_bed versus double_bed, tv_stand versus dresser, and so on.\nWe decided a good starting point would be to determine object locations in the 2D space, and see where we could go from there. We intended to then train for CoGs, but we had limited time with the SUMO challenge deadline being mid-December, so we decided to see how well we could perform by using the following pipeline:\n Project 3D bounding boxes into 2D space to generate a 2D dataset Train a Faster-R-CNN network to detect objects on the 2D dataset Project the 2D coordinates back into 3D, do some simple post-processing to prevent things like walls and floors from being in the bounding box Train Regressors to help correct the coordinates on a per-category basis  Results On December 18th, we found out that the SUMO challege deadline would be pushed back to January 14th. We continued work on step (3) but didn't get very far in step (4), so our final pipeline consists of steps (1) through (3). We made our submission on Sunday, January 13th.\nWe found out that we were narrowly beat by the Princeton Vision Lab for 1st place, leaving us in 2nd place for our cateogry.\nVisual Results in 3D Below are our results in the 3D space. On the left, we have a red bounding box, which is our detection. On the right in green we have the ground truth bounding boxes for that same scene.\nVisual Results in 2D Below are some visual results we've gotten in the 2D space training the Faster-R-CNN network.\nAs you can see, the network performs fairly well. Mean AP was about 23% which is reasonable given the enormous dataset size and the skewed distribution. One aspect that particularly complicates this challenge are the walls and floors, which are object categories, but the coordinates are often outside of single-frame views, which is exactly what this network was trained to perform on.\n","date":1567382400,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1567487372,"objectID":"b9b26d2a3237290550ea3fd07978686a","permalink":"/project/sumo/","publishdate":"2019-09-02T00:00:00Z","relpermalink":"/project/sumo/","section":"project","summary":"Facebook's Scene Understanding and Modeling Challenge.","tags":["computer vision","machine learning","research"],"title":"SUMO Challenge","type":"project"},{"authors":null,"categories":null,"content":"Background: Graph Theory was among my favorite topics during my undergraduate studies, and in Fall 2016, I managed to find research that would build on my interests in that area as well as leverage the Systems background I had (from one of concentration areas: Devices).\nI joined Dr. Oded Green that term, and we began work immediately on Streaming Graphs (also known as Dynamic Graphs). These are graphs where the Nodes $V$ and Edges $E$ change over time.\nProblem: Betweenness Centrality on Streaming Graphs Betweenness Centrality(BC) is a measure of a node's centrality in a graph based on it's presence in shortest paths.\nThink of it as the hub that connects many different transportation lines. The more dependent other transportation lines are on a given hub, the more central that hub is to the network.\nOn a static graph, we can compute the BC values for each node pretty easily (in terms of time complexity). However, real-world graphs like Facebook's Social Network Graph contain hundreds of millions of nodes and billions of edges. If we wanted up-to-date BC values for graphs of this scale, re-computing BC each time a node/edge is inserted or delete becomes infeasible.\nSo that's our task: Given a graph and then a sequence of insertions/deletions, can we accurately compute the BC values without recomputing on the entire graph?\nApproach: We created a framework called cuStinger (a portmanteau of Cuda and Stinger), which served as the backbone of our adventure in getting Streaming BC going.\nUsing this framework (which saved us largely from writing repetitive Cuda code), we implemented the algorithm as described here.\nChallenges: Since we were using Nvidia GPUs and Cuda under the hood, we had various challenges with race conditions, mutex locks, and validating results.\nResults: By the end of that year, we managed to have a running version that handled most edge cases of streaming graphs. There were some we hadn't implemented yet when I left the lab.\nA few weeks later, the lab moved onto a new framework (developed in-house with Oded and his lab), Hornet.\nLessons Learned  Parallel Computation comes with some challenges, be ready Advances in GPU programming are opening doors to many new areas ripe for exploration ALWAYS write tests to validate results (we compared our Streaming BC results to our Static BC at each insertion/deletion)  Tools Used  C/C++ Cuda cuStinger framework  ","date":1567296000,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1567485122,"objectID":"4ad9483811836389d75e55c8ef4ed7aa","permalink":"/project/hpc/","publishdate":"2019-09-01T00:00:00Z","relpermalink":"/project/hpc/","section":"project","summary":"Computing Betweenness Centrality on Streaming Graphs","tags":["hpc","research"],"title":"Betweenness Centrality for Streaming Graphs","type":"project"},{"authors":null,"categories":null,"content":"In Fall 2018, I decided to apply to be a speaker for TEDxGeorgiaTech's Fall speaker salon. I was chosen as one of the 6 speakers among 70 applicants.\nFor the 6 weeks that followed, I rewrote my speech several times over. I changed it drastically from what it started off as, added entirely new ideas, and overall realized that the focus of the talk had to be not my experience, but rather what others should take from it.\nFinally, on November 4th, 2018, my hard work paid off. I was the final speaker for the night, so I ended the show. My talk, Compounding Interest: How Instilling Drive Goes a Long Way tried to strike a delicate balance between being informative and being relatable. My focus was on the importance of instilling drive and the cascading effect that it had on educating society.\nYou can find my full talk here.\nAdditionally, I found out in February, 2019 that I was chosen among the 6 speakers from last Fall to speak again at the TedXGeorgiaTech Conference held on April 13th, 2019. I'm was ecstatic about the chance to revise my talk and give it one more time in front of an even larger crowd!\nThe revised talk was posted here in late July.\n","date":1567296000,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1567485122,"objectID":"beaaec28bcf9e35634a1be35667fa86b","permalink":"/post/ted/","publishdate":"2019-09-01T00:00:00Z","relpermalink":"/post/ted/","section":"post","summary":"In Fall 2018, I decided to apply to be a speaker for TEDxGeorgiaTech's Fall speaker salon. I was chosen as one of the 6 speakers among 70 applicants.\nFor the 6 weeks that followed, I rewrote my speech several times over. I changed it drastically from what it started off as, added entirely new ideas, and overall realized that the focus of the talk had to be not my experience, but rather what others should take from it.","tags":null,"title":"Speaking at TEDxGeorgiaTech's Fall 2018 Speaker Salon","type":"post"},{"authors":["Lyne P. Tchapmi","Daniel Huber","Richard Skarbez","Ilke Demir","Jimmy Wu","Xingyuan Sun","Muhammad \"Osama\" Sakhi","Zhile Ren","Shuran Song","Thomas Funkhouser","Silvio Savarese","Frank Dellaert"],"categories":null,"content":"IMPORTANT This paper was being worked on until May 2019. At that time, the competition organizer, Facebook, faced a lawsuit for the creation of the dataset. To mitigate further risk of litigation, this paper was left unpublished and incomplete indefinitely.\nThe abstract presented above is from our working draft of the paper.\n","date":1559779200,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1577685153,"objectID":"51de3b4b0f038cfd845e2fa2218948a3","permalink":"/publication/sumo/","publishdate":"2017-01-01T00:00:00Z","relpermalink":"/publication/sumo/","section":"publication","summary":"Dataset paper for the Scene Understanding and Modeling (SUMO) Challenge by Facebook.","tags":["research","computer vision","machine learning"],"title":"Sumo","type":"publication"},{"authors":[],"categories":[],"content":"Welcome to Slides Academic\n Features  Efficiently write slides in Markdown 3-in-1: Create, Present, and Publish your slides Supports speaker notes Mobile friendly slides   Controls  Next: Right Arrow or Space Previous: Left Arrow Start: Home Finish: End Overview: Esc Speaker notes: S Fullscreen: F Zoom: Alt + Click PDF Export: E   Code Highlighting Inline code: variable\nCode block:\nporridge = \u0026#34;blueberry\u0026#34; if porridge == \u0026#34;blueberry\u0026#34;: print(\u0026#34;Eating...\u0026#34;)  Math In-line math: $x + y = z$\nBlock math:\n$$ f\\left( x \\right) = ;\\frac{{2\\left( {x + 4} \\right)\\left( {x - 4} \\right)}}{{\\left( {x + 4} \\right)\\left( {x + 1} \\right)}} $$\n Fragments Make content appear incrementally\n{{% fragment %}} One {{% /fragment %}} {{% fragment %}} **Two** {{% /fragment %}} {{% fragment %}} Three {{% /fragment %}} Press Space to play!\nOne Two Three  A fragment can accept two optional parameters:\n class: use a custom style (requires definition in custom CSS) weight: sets the order in which a fragment appears   Speaker Notes Add speaker notes to your presentation\n{{% speaker_note %}} - Only the speaker can read these notes - Press `S` key to view {{% /speaker_note %}} Press the S key to view the speaker notes!\n Only the speaker can read these notes Press S key to view    Themes  black: Black background, white text, blue links (default) white: White background, black text, blue links league: Gray background, white text, blue links beige: Beige background, dark text, brown links sky: Blue background, thin dark text, blue links    night: Black background, thick white text, orange links serif: Cappuccino background, gray text, brown links simple: White background, black text, blue links solarized: Cream-colored background, dark green text, blue links   Custom Slide Customize the slide style and background\n{{\u0026lt; slide background-image=\u0026#34;/img/boards.jpg\u0026#34; \u0026gt;}} {{\u0026lt; slide background-color=\u0026#34;#0000FF\u0026#34; \u0026gt;}} {{\u0026lt; slide class=\u0026#34;my-style\u0026#34; \u0026gt;}}  Custom CSS Example Let's make headers navy colored.\nCreate assets/css/reveal_custom.css with:\n.reveal section h1, .reveal section h2, .reveal section h3 { color: navy; }  Questions? Ask\nDocumentation\n","date":1549324800,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1566957583,"objectID":"0e6de1a61aa83269ff13324f3167c1a9","permalink":"/slides/example/","publishdate":"2019-02-05T00:00:00Z","relpermalink":"/slides/example/","section":"slides","summary":"An introduction to using Academic's Slides feature.","tags":[],"title":"Slides","type":"slides"}]
>>>>>>> Local
